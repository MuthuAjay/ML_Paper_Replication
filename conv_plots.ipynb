{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a9dfd35-5a03-47a6-84f4-65e170652617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from itertools import repeat\n",
    "from typing import Optional, List, Tuple\n",
    "\n",
    "\n",
    "class Relu:\n",
    "\n",
    "    def __call__(self,\n",
    "                 X: torch.Tensor):\n",
    "        return torch.clamp(X, min=0)\n",
    "\n",
    "    def backward(self,\n",
    "                 dZ: torch.Tensor):\n",
    "        return (dZ > 0).float()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "\n",
    "    def __call__(self,\n",
    "                 X: torch.Tensor,\n",
    "                 dim: int):\n",
    "        X = X - torch.max(X, dim=1, keepdims=True).values\n",
    "        sof = torch.exp(X) / torch.sum(torch.exp(X), dim=dim, keepdims=True)\n",
    "        return sof\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class OptimizerSG:\n",
    "\n",
    "    def __init__(self,\n",
    "                 params: Optional[List],\n",
    "                 lr: float = 0.1):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.data -= self.lr * param.grad\n",
    "\n",
    "\n",
    "class Flatten:\n",
    "\n",
    "    def __call__(self,\n",
    "                 X: torch.Tensor):\n",
    "        self.X = X\n",
    "        self.out = X.view(X.shape[0], -1)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self,\n",
    "                 dZ: torch.Tensor):\n",
    "        dX = dZ.view(self.X.size())\n",
    "        return dX\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self,\n",
    "                 layers: List):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self,\n",
    "                 X: torch.Tensor):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        self.out = X\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self,\n",
    "                 fan_in: int,\n",
    "                 fan_out: int,\n",
    "                 bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) // fan_in ** 0.5\n",
    "        self.bias = torch.randn(fan_out) if bias else None\n",
    "\n",
    "    def __call__(self,\n",
    "                 X: torch.Tensor):\n",
    "        self.last_input = X\n",
    "        self.out = X @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, d_L_d_out):\n",
    "        # d_L_d_weights = torch.matmul(self.last_input.t(), d_L_d_out)\n",
    "\n",
    "        d_L_d_weights = self.last_input.T @ d_L_d_out\n",
    "        d_L_d_biases = torch.sum(d_L_d_out, dim=0)\n",
    "        d_L_d_input = d_L_d_out @ self.weight.T\n",
    "\n",
    "        return d_L_d_input, d_L_d_weights, d_L_d_biases\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "\n",
    "    def __call__(self,\n",
    "                 y_pred: torch.Tensor,\n",
    "                 y_true: torch.Tensor\n",
    "                 ):\n",
    "        n_samples = y_pred.shape[0]\n",
    "        log_likelihood = -torch.log(y_pred[range(n_samples), y_true])\n",
    "        return torch.sum(log_likelihood) / n_samples\n",
    "\n",
    "    def backward(self,\n",
    "                 y_pred: torch.Tensor,\n",
    "                 y_true: torch.Tensor\n",
    "                 ):\n",
    "        n_samples = y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        grad = softmax(y_pred, dim=1)\n",
    "        grad[range(n_samples), y_true] -= 1\n",
    "        grad = grad / n_samples\n",
    "        return grad\n",
    "\n",
    "    def paramerters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class MaxPool2d:\n",
    "\n",
    "    def __init__(self, kernel_size: int | Tuple[int, int], stride: int | Tuple[int, int]):\n",
    "        self.kernel_size = tuple(kernel_size) if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = tuple(stride) if isinstance(stride, tuple) else (stride, stride)\n",
    "        self.kh, self.kw = self.kernel_size\n",
    "        self.sh, self.sw = self.stride\n",
    "        self.padded_height, self.padded_width = None, None\n",
    "\n",
    "    def prepare_submatrix(self, X: torch.Tensor):\n",
    "        B, C, ih, iw = X.shape\n",
    "        oh = (ih - self.kh) // self.sh + 1\n",
    "        ow = (iw - self.kw) // self.sw + 1\n",
    "        subM = X.unfold(2, self.kh, self.sh).unfold(3, self.kw, self.sw)\n",
    "        return subM\n",
    "\n",
    "    def __call__(self, X: torch.Tensor):\n",
    "        self.X = X\n",
    "        subM = self.prepare_submatrix(X)\n",
    "        return subM.max(dim=-1).values.max(dim=-1).values\n",
    "\n",
    "    def add_padding(self, x: torch.Tensor, padding: int):\n",
    "        padding = tuple(repeat(padding, 4))\n",
    "        batch_size, in_channels, original_height, original_width = x.size()\n",
    "        padded_height = original_height + padding[0] + padding[1]\n",
    "        padded_width = original_width + padding[2] + padding[3]\n",
    "\n",
    "        if (self.padded_height and self.padded_width) is None:\n",
    "            self.padded_height, self.padded_width = padded_height, padded_width\n",
    "\n",
    "        padded_x = torch.zeros((batch_size, in_channels, padded_height, padded_width), dtype=x.dtype)\n",
    "        padded_x[:, :, padding[0]:padding[0] + original_height, padding[2]:padding[2] + original_width] = x\n",
    "        return padded_x\n",
    "\n",
    "    def prepare_mask(self, subM: torch.Tensor):\n",
    "        B, C, oh, ow, kh, kw = subM.shape\n",
    "        a = torch.reshape(subM, (-1, kh * kw))\n",
    "        idx = torch.argmax(a, dim=1)\n",
    "        b = torch.zeros_like(a)\n",
    "        b[torch.arange(b.shape[0]), idx] = 1\n",
    "        mask = b.view(B, C, oh, ow, kh, kw)\n",
    "        return mask\n",
    "\n",
    "    def mask_dXp(self, mask: torch.Tensor, dz: torch.Tensor):\n",
    "        dz_expanded = dz.unsqueeze(-1).unsqueeze(-1).expand_as(mask)\n",
    "        dXp = dz_expanded * mask\n",
    "        return dXp\n",
    "\n",
    "    def maxpool_backprop(self, dZ: torch.Tensor, X: torch.Tensor):\n",
    "        Xp = self.add_padding(X, self.kernel_size[0])\n",
    "        subM = self.prepare_submatrix(Xp)\n",
    "        mask = self.prepare_mask(subM)\n",
    "        dXp = self.mask_dXp(mask, dZ)\n",
    "        return dXp\n",
    "\n",
    "    def padding_backward(self, dXp: torch.Tensor):\n",
    "        B, C, ih, iw = self.X.shape\n",
    "        dX = dXp[:, :, self.padded_height:ih, self.padded_width:iw]\n",
    "        return dX\n",
    "\n",
    "    def backward(self, dL_dout):\n",
    "        Batch, num_channels, input_height, input_width = self.X.shape\n",
    "        dL_dinput = torch.zeros_like(self.X)\n",
    "        output_height = (input_height - self.kh) // self.sh + 1\n",
    "        output_width = (input_width - self.kw) // self.sw + 1\n",
    "\n",
    "        # Extract patches from the input tensor\n",
    "        subM = self.prepare_submatrix(self.X)\n",
    "\n",
    "        # Create the mask for the max pooling operation\n",
    "        mask = self.prepare_mask(subM)\n",
    "\n",
    "        # Expand dL_dout to match the shape of mask and perform element-wise multiplication\n",
    "        dL_dout_expanded = dL_dout.unsqueeze(-1).unsqueeze(-1).expand_as(mask)\n",
    "        dL_dinput_unfolded = dL_dout_expanded * mask\n",
    "\n",
    "        # Combine the unfolded gradients to form the final gradient\n",
    "        dL_dinput = dL_dinput_unfolded.contiguous().view(Batch, num_channels, output_height, output_width, self.kh,\n",
    "                                                         self.kw)\n",
    "        dL_dinput = dL_dinput.permute(0, 1, 2, 4, 3, 5).contiguous().view(Batch, num_channels, output_height * self.kh,\n",
    "                                                                          output_width * self.kw)\n",
    "\n",
    "        # Reduce the overlapping areas by summing them\n",
    "        result = torch.zeros_like(self.X)\n",
    "        for i in range(self.kh):\n",
    "            for j in range(self.kw):\n",
    "                result[:, :, i::self.kh, j::self.kw] += dL_dinput[:, :, i::self.kh, j::self.kw]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Conv2d:\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 0,\n",
    "                 dilation: int = 1,\n",
    "                 groups: int = 1,\n",
    "                 bias: bool = True) -> None:\n",
    "        self.output_shape = None\n",
    "        self.Ow = None\n",
    "        self.Oh = None\n",
    "        self.iw = None\n",
    "        self.ih = None\n",
    "        self.C = None\n",
    "        self.B = None\n",
    "        self.input_shape = None\n",
    "        self.input_shape_x = None\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.kh, self.kw = self.kernel_size\n",
    "        self.stride = stride if isinstance(stride, tuple) else (stride, stride)\n",
    "        self.sh, self.sw = self.stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.weights, self.bias = self.initialise_parameters()\n",
    "\n",
    "    def initialise_parameters(self, bias: bool = True):\n",
    "        # return (torch.randn(self.out_channels, self.in_channels // self.groups, *self.kernel_size, requires_grad=True),\n",
    "        #         torch.zeros(self.out_channels,self.Oh, self.Ow, requires_grad=True) if not bias else torch.randn(self.out_channels,self.Oh, self.Ow, requires_grad=True))\n",
    "        return (torch.randn(self.out_channels, self.in_channels // self.groups, *self.kernel_size, requires_grad=True),\n",
    "                torch.zeros(self.out_channels, requires_grad=True) if not bias else torch.randn(self.out_channels,\n",
    "                                                                                                requires_grad=True))\n",
    "\n",
    "    def get_padding_dimensions(self,\n",
    "                               input_shape: torch.Tensor.size,\n",
    "                               kernel_size: Tuple,\n",
    "                               s=(1, 1),\n",
    "                               padding: int | Tuple = None):\n",
    "        if len(input_shape) == 4:\n",
    "            B, C, ih, iw = input_shape\n",
    "        if len(input_shape) == 3:\n",
    "            C, ih, iw = input_shape\n",
    "\n",
    "        kh, kw = kernel_size\n",
    "        sh, sw = s\n",
    "        if padding is None:\n",
    "            p = self.padding\n",
    "        else:\n",
    "            p = padding\n",
    "\n",
    "        if isinstance(p, int):\n",
    "            pt, pb, pl, pr = p, p, p, p\n",
    "        elif isinstance(p, tuple):\n",
    "            ph, pw = p\n",
    "            pt, pb = ph // 2, (ph + 1) // 2\n",
    "            pl, pr = pw // 2, (pw + 1) // 2\n",
    "        elif p == 'valid':\n",
    "            pt, pb = 0, 0\n",
    "            pl, pr = 0, 0\n",
    "\n",
    "        elif p == 'same':\n",
    "            ph = (sh - 1) * ih + kh - sh\n",
    "            pw = (sw - 1) * iw + kw - sw\n",
    "\n",
    "            pt, pb = ph // 2, (ph + 1) // 2\n",
    "            pl, pr = pw // 2, (pw + 1) // 2\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Incorrect padding type. Allowed types are only 'same', 'valid', an integer or a tuple of length 2.\")\n",
    "\n",
    "        if len(input_shape) == 4:\n",
    "            output_shape = (B, C, ih + pt + pb, iw + pl + pr)\n",
    "        elif len(input_shape) == 4:\n",
    "            output_shape = (C, ih + pt + pb + iw + pl + pr)\n",
    "\n",
    "        return output_shape, (pt, pb, pl, pr)\n",
    "\n",
    "    def get_dimensions(self, input_shape: torch.Tensor):\n",
    "        self.input_shape_x = input_shape.shape\n",
    "        self.input_shape, _ = self.get_padding_dimensions(self.input_shape_x, self.kernel_size, self.stride)\n",
    "\n",
    "        if len(self.input_shape) == 3:\n",
    "            self.C, self.ih, self.iw = self.input_shape\n",
    "        elif len(self.input_shape) == 4:\n",
    "            self.B, self.C, self.ih, self.iw = self.input_shape\n",
    "\n",
    "        self.Oh = (self.ih - self.kh) // self.sh + 1\n",
    "        self.Ow = (self.iw - self.kw) // self.sw + 1\n",
    "\n",
    "        if len(self.input_shape) == 3:\n",
    "            self.output_shape = (self.out_channels, self.Oh, self.Ow)\n",
    "        elif len(self.input_shape) == 4:\n",
    "            self.output_shape = (self.B, self.out_channels, self.Oh, self.Ow)\n",
    "\n",
    "    def prepare_subMatrix(self, X: torch.Tensor, Kh: int, Kw: int, s):\n",
    "        B, C, ih, iw = X.shape\n",
    "        sh, sw = s\n",
    "\n",
    "        Oh = (ih - Kh) // sh + 1\n",
    "        Ow = (iw - Kw) // sw + 1\n",
    "\n",
    "        strides = (C * ih * iw, iw * ih, iw * sh, sw, iw, 1)\n",
    "        subM = torch.as_strided(X,\n",
    "                                size=(B, C, Oh, Ow, Kh, Kw),\n",
    "                                stride=strides)\n",
    "        return subM\n",
    "\n",
    "    def convolve(self, X: torch.Tensor, K: torch.Tensor, s: Tuple = (1, 1), mode: str = 'back'):\n",
    "        F, Kc, Kh, Kw = K.shape\n",
    "        subM = self.prepare_subMatrix(X, Kh, Kw, s)\n",
    "        if mode == 'front':\n",
    "            return torch.einsum('fckl,mcijkl->mfij', K, subM)\n",
    "        elif mode == 'back':\n",
    "            return torch.einsum('fdkl,mcijkl->mdij', K, subM)\n",
    "        elif mode == 'param':\n",
    "            return torch.einsum('mfkl,mcijkl->fcij', K, subM)\n",
    "\n",
    "    def padding_forward(self, X: torch.Tensor, kernel_size, s=(1, 1), padding=None) -> torch.Tensor:\n",
    "        self.input_shape_before_padding = X.shape\n",
    "        B, C, ih, iw = self.input_shape_before_padding\n",
    "        self.output_shape_padded, (self.pt, self.pb, self.pl, self.pr) = self.get_padding_dimensions(\n",
    "            self.input_shape_before_padding, kernel_size, s, padding=padding)\n",
    "\n",
    "        zeros_r = torch.zeros((B, C, ih, self.pr), dtype=X.dtype, device=X.device)\n",
    "        zeros_l = torch.zeros((B, C, iw, self.pl), dtype=X.dtype, device=X.device)\n",
    "        zeros_t = torch.zeros((B, C, self.pt, iw + self.pl + self.pr), dtype=X.dtype, device=X.device)\n",
    "        zeros_b = torch.zeros((B, C, self.pb, iw + self.pl + self.pr), dtype=X.dtype, device=X.device)\n",
    "\n",
    "        Xp = torch.concat((X, zeros_r), dim=3)\n",
    "        Xp = torch.concat((zeros_l, Xp), dim=3)\n",
    "        Xp = torch.concat((zeros_t, Xp), dim=2)\n",
    "        Xp = torch.concat((Xp, zeros_b), dim=2)\n",
    "\n",
    "        return Xp\n",
    "\n",
    "    def padding_backward(self, dXp: torch.Tensor):\n",
    "        B, C, ih, iw = self.input_shape\n",
    "        dX = dXp[:, :, self.pt:self.pt + ih, self.pl:self.pl + iw]\n",
    "        return dX\n",
    "\n",
    "    def dilate2D(self, X: torch.Tensor, Dr=(1, 1)) -> torch.Tensor:\n",
    "        dh, dw = Dr\n",
    "        B, C, H, W = X.shape\n",
    "\n",
    "        if dw > 1:\n",
    "            Xd_w = torch.zeros((B, C, H, W + (W - 1) * (dw - 1)), dtype=X.dtype, device=X.device)\n",
    "            Xd_w[:, :, :, ::dw] = X\n",
    "        else:\n",
    "            Xd_w = X\n",
    "\n",
    "        if dh > 1:\n",
    "            Xd_h = torch.zeros((B, C, H + (H - 1) * (dh - 1), Xd_w.shape[-1]), dtype=X.dtype, device=X.device)\n",
    "            Xd_h[:, :, ::dh, :] = Xd_w\n",
    "        else:\n",
    "            Xd_h = Xd_w\n",
    "\n",
    "        return Xd_h\n",
    "\n",
    "    def dZ_D_dX(self, dZ_D: torch.Tensor, ih: int, iw: int) -> torch.Tensor:\n",
    "        _, _, Hd, Wd = dZ_D.shape\n",
    "        ph = ih - Hd + self.kh - 1\n",
    "        pw = iw - Wd + self.kw - 1\n",
    "\n",
    "        dZ_Dp = self.padding_forward(dZ_D, self.kernel_size, self.stride, (ph, pw))\n",
    "        k_rotated = self.weights.flip([2, 3])\n",
    "        dXp = self.convolve(dZ_Dp, k_rotated, mode='back')\n",
    "        dX = self.padding_backward(dXp)\n",
    "\n",
    "        return dX\n",
    "\n",
    "    def __call__(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        self.X = X\n",
    "        self.get_dimensions(X)\n",
    "        Xp = self.padding_forward(X, self.kernel_size, self.stride, self.padding)\n",
    "        self.Z = self.convolve(Xp, self.weights, self.stride, mode='front')\n",
    "\n",
    "        if self.bias is not None:\n",
    "            return self.Z + self.bias.view(1, -1, 1, 1)  # sum should be done on the last layer\n",
    "\n",
    "        return self.Z\n",
    "\n",
    "    def backward(self, dZ: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        Xp = self.padding_forward(self.X, self.kernel_size, self.stride)\n",
    "\n",
    "        B, C, ih, iw = Xp.shape\n",
    "\n",
    "        # Dilate dZ (dZ -> dZ_D)\n",
    "        dZ_D = self.dilate2D(dZ, Dr=self.stride)\n",
    "        dX = self.dZ_D_dX(dZ_D, ih, iw)\n",
    "\n",
    "        # Gradient K\n",
    "        _, _, Hd, Wd = dZ_D.shape\n",
    "\n",
    "        ph = self.ih - Hd - self.kh + 1\n",
    "        pw = self.iw - Wd - self.kw + 1\n",
    "\n",
    "        dZ_Dp = self.padding_forward(dZ_D, self.kernel_size, self.stride, padding=(ph, pw))\n",
    "        self.dK = self.convolve(Xp, dZ_Dp, mode='param')\n",
    "\n",
    "        # gradient db\n",
    "        self.db = torch.sum(dZ, dim=[0,2,3])\n",
    "\n",
    "        return dX, self.dK, self.db\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "def backward(logits):\n",
    "    dlogits = loss.backward(logits,y)\n",
    "    d_L_d_input, d_L_d_weights, d_L_d_biases = classifier.layers[-1].backward(dlogits)\n",
    "    dflatten = classifier.layers[-2].backward(d_L_d_input)\n",
    "\n",
    "    # backward pass through maxpool\n",
    "    dmaxp2 = model.layers[-1].backward(dflatten)\n",
    "    drel2 = model.layers[-2].backward(dmaxp2)\n",
    "    dconv2, dconv_w2, dconv_b2 = model.layers[-3].backward(drel2)\n",
    "    drel1 = model.layers[-3].backward(dconv2)\n",
    "    dconv1, dconv_w1, dconv_b1 = model.layers[-5].backward(drel2)\n",
    "\n",
    "    grads = [dconv_w1, dconv_b1, dconv_w2, dconv_b2,\n",
    "             d_L_d_weights, d_L_d_biases]\n",
    "    return grads\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "\n",
    "    def __init__(self, optimizer_type: str = None):\n",
    "        if optimizer_type is None:\n",
    "            self.optimizer_type = 'SGD'\n",
    "        else:\n",
    "            self.optimizer_type = optimizer_type\n",
    "\n",
    "    def SGD(self,\n",
    "            parameters: List[torch.Tensor],\n",
    "            grads: List[torch.Tensor],\n",
    "            momentum: int = 0.1,\n",
    "            lr: float = 0.1):\n",
    "        for p, grad in zip(parameters, grads):                                                                                                                                    \n",
    "            p.data += -lr * grad\n",
    "        return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e77890cf-93e2-4bbd-8065-4f366626f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "124073\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "model = Sequential([\n",
    "    Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1, dilation=1),\n",
    "    Relu(),\n",
    "    Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1, dilation=1),\n",
    "    Relu(),\n",
    "    MaxPool2d(2, 2),\n",
    "])\n",
    "classifier = Sequential([\n",
    "    Flatten(),\n",
    "    Linear(fan_in=40960,\n",
    "           fan_out=3)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "    classifier.layers[-1].weight *= 0.1\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "parameters = model.parameters() + classifier.parameters()\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "y = torch.randint(0, 3, (30,))\n",
    "x = torch.randn(30, 3, 128, 128)\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4d53b17-e22e-4241-b464-1f9c15949485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "tensor(nan, grad_fn=<DivBackward0>)\n",
      "[tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>), tensor(nan, grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for i in range(num_epochs):\n",
    "    logits = classifier(model(x))\n",
    "\n",
    "    loss = CrossEntropyLoss()\n",
    "    lossi = loss(logits, y)\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    grads = backward(logits)\n",
    "    optimizer = Optimizer()\n",
    "    parameters = optimizer.SGD(parameters=parameters, grads=grads)\n",
    "    losses.append(lossi)\n",
    "    print(lossi)\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0be38b-97bf-47b2-a3e1-868bb47376ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09a0b8c7-a11b-42e6-a4e2-cbdde3b79bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159e2b7f510>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_np = [ten.detach().numpy() for ten in losses]\n",
    "plt.plot(losses_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37c80f-7582-47d2-b160-c3d101b18b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
